{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP5qL++zePSNSAZViibc/g3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"33VhYPeu7ze4","executionInfo":{"status":"ok","timestamp":1707233742434,"user_tz":-330,"elapsed":10,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"2eb57c79-9890-4d19-898b-13076a3c9e8a"},"outputs":[{"output_type":"stream","name":"stdout","text":["{1: 2, 2: 3, 3: 3, 4: 3, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1}\n","{'this': 1, 'is': 2, 'a': 3, 'test': 4, 'to': 5, 'see': 6, 'if': 7, 'will': 8, 'work': 9}\n"]}],"source":["vocab = {}  # maps word to integer representing it\n","word_encoding = 1\n","def bag_of_words(text):\n","  global word_encoding\n","\n","  words = text.lower().split(\" \")  # create a list of all of the words in the text, well assume there is no grammar in our text for this example\n","  bag = {}  # stores all of the encodings and their frequency\n","\n","  for word in words:\n","    if word in vocab:\n","      encoding = vocab[word]  # get encoding from vocab\n","    else:\n","      vocab[word] = word_encoding\n","      encoding = word_encoding\n","      word_encoding += 1\n","\n","    if encoding in bag:\n","      bag[encoding] += 1\n","    else:\n","      bag[encoding] = 1\n","\n","  return bag\n","\n","text = \"this is a test to see if this test will work is is test a a\"\n","bag = bag_of_words(text)\n","print(bag)\n","print(vocab)"]},{"cell_type":"code","source":["positive_review = \"I thought the movie was going to be bad but it was actually amazing\"\n","negative_review = \"I thought the movie was going to be amazing but it was actually bad\"\n","\n","pos_bag = bag_of_words(positive_review)\n","neg_bag = bag_of_words(negative_review)\n","\n","print(\"Positive:\", pos_bag)\n","print(\"Negative:\", neg_bag)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"whG_KHSj-tPX","executionInfo":{"status":"ok","timestamp":1707233742435,"user_tz":-330,"elapsed":9,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"a14a9820-4219-4ba9-da9c-ae80f5d7d181"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Positive: {10: 1, 11: 1, 12: 1, 13: 1, 14: 2, 15: 1, 5: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1}\n","Negative: {10: 1, 11: 1, 12: 1, 13: 1, 14: 2, 15: 1, 5: 1, 16: 1, 21: 1, 18: 1, 19: 1, 20: 1, 17: 1}\n"]}]},{"cell_type":"code","source":["vocab = {}\n","word_encoding = 1\n","def one_hot_encoding(text):\n","  global word_encoding\n","\n","  words = text.lower().split(\" \")\n","  encoding = []\n","\n","  for word in words:\n","    if word in vocab:\n","      code = vocab[word]\n","      encoding.append(code)\n","    else:\n","      vocab[word] = word_encoding\n","      encoding.append(word_encoding)\n","      word_encoding += 1\n","\n","  return encoding\n","\n","text = \"this is a test to see if this test will work is is test a a\"\n","encoding = one_hot_encoding(text)\n","print(encoding)\n","print(vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yv2cpE3__yFc","executionInfo":{"status":"ok","timestamp":1707233742435,"user_tz":-330,"elapsed":8,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"59bc2fe9-9a9b-42bf-cfe6-4e69e9c839c1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 2, 3, 4, 5, 6, 7, 1, 4, 8, 9, 2, 2, 4, 3, 3]\n","{'this': 1, 'is': 2, 'a': 3, 'test': 4, 'to': 5, 'see': 6, 'if': 7, 'will': 8, 'work': 9}\n"]}]},{"cell_type":"code","source":["positive_review = \"I thought the movie was going to be bad but it was actually amazing\"\n","negative_review = \"I thought the movie was going to be amazing but it was actually bad\"\n","\n","pos_encode = one_hot_encoding(positive_review)\n","neg_encode = one_hot_encoding(negative_review)\n","\n","print(\"Positive:\", pos_encode)\n","print(\"Negative:\", neg_encode)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3k9YXls9ADLj","executionInfo":{"status":"ok","timestamp":1707233742435,"user_tz":-330,"elapsed":6,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"06dda9d7-b85d-415a-a4de-294bc169d8d4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Positive: [10, 11, 12, 13, 14, 15, 5, 16, 17, 18, 19, 14, 20, 21]\n","Negative: [10, 11, 12, 13, 14, 15, 5, 16, 21, 18, 19, 14, 20, 17]\n"]}]},{"cell_type":"markdown","source":["# Sentiment Analysis"],"metadata":{"id":"0io_yxZ_Adb1"}},{"cell_type":"code","source":["%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n","from keras.datasets import imdb\n","from keras.preprocessing import sequence\n","import keras\n","import tensorflow as tf\n","import os\n","import numpy as np\n","\n","VOCAB_SIZE = 88584\n","\n","MAXLEN = 250\n","BATCH_SIZE = 64\n","\n","(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8VLS7rCiAf38","executionInfo":{"status":"ok","timestamp":1707233752539,"user_tz":-330,"elapsed":10109,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"3399da97-598f-40c2-b39a-84d99bde05b3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17464789/17464789 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["train_data = sequence.pad_sequences(train_data, MAXLEN)\n","test_data = sequence.pad_sequences(test_data, MAXLEN)"],"metadata":{"id":"HhxjEH5vB28x","executionInfo":{"status":"ok","timestamp":1707233753801,"user_tz":-330,"elapsed":1266,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n","    tf.keras.layers.LSTM(32),\n","    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n","])"],"metadata":{"id":"0pG7w7zPCVaA","executionInfo":{"status":"ok","timestamp":1707233756596,"user_tz":-330,"elapsed":2798,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4NYQlyDaDaG0","executionInfo":{"status":"ok","timestamp":1707233756596,"user_tz":-330,"elapsed":11,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"95c1ecaf-6ae9-47b7-f5b8-d33262163535"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, None, 32)          2834688   \n","                                                                 \n"," lstm (LSTM)                 (None, 32)                8320      \n","                                                                 \n"," dense (Dense)               (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2843041 (10.85 MB)\n","Trainable params: 2843041 (10.85 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\n","\n","history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i6fbefx5DcIs","executionInfo":{"status":"ok","timestamp":1707233895965,"user_tz":-330,"elapsed":139377,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"45e23c4d-e6d7-4d7b-c0a1-668b92d9dba1"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","625/625 [==============================] - 48s 71ms/step - loss: 0.4471 - acc: 0.7807 - val_loss: 0.3054 - val_acc: 0.8728\n","Epoch 2/10\n","625/625 [==============================] - 17s 27ms/step - loss: 0.2576 - acc: 0.9008 - val_loss: 0.3006 - val_acc: 0.8822\n","Epoch 3/10\n","625/625 [==============================] - 12s 20ms/step - loss: 0.2024 - acc: 0.9253 - val_loss: 0.3566 - val_acc: 0.8578\n","Epoch 4/10\n","625/625 [==============================] - 11s 17ms/step - loss: 0.1642 - acc: 0.9436 - val_loss: 0.2914 - val_acc: 0.8770\n","Epoch 5/10\n","625/625 [==============================] - 9s 15ms/step - loss: 0.1405 - acc: 0.9521 - val_loss: 0.3340 - val_acc: 0.8536\n","Epoch 6/10\n","625/625 [==============================] - 10s 16ms/step - loss: 0.1178 - acc: 0.9617 - val_loss: 0.3222 - val_acc: 0.8766\n","Epoch 7/10\n","625/625 [==============================] - 9s 14ms/step - loss: 0.0989 - acc: 0.9685 - val_loss: 0.3477 - val_acc: 0.8750\n","Epoch 8/10\n","625/625 [==============================] - 8s 13ms/step - loss: 0.0825 - acc: 0.9749 - val_loss: 0.3583 - val_acc: 0.8706\n","Epoch 9/10\n","625/625 [==============================] - 8s 13ms/step - loss: 0.0718 - acc: 0.9776 - val_loss: 0.3832 - val_acc: 0.8726\n","Epoch 10/10\n","625/625 [==============================] - 8s 13ms/step - loss: 0.0615 - acc: 0.9812 - val_loss: 0.5278 - val_acc: 0.8362\n"]}]},{"cell_type":"code","source":["results = model.evaluate(test_data, test_labels)\n","print(results)"],"metadata":{"id":"prJs34R6D1CB","executionInfo":{"status":"ok","timestamp":1707233895966,"user_tz":-330,"elapsed":24,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["word_index = imdb.get_word_index()\n","\n","def encode_text(text):\n","  tokens = keras.preprocessing.text.text_to_word_sequence(text)\n","  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n","  return sequence.pad_sequences([tokens], MAXLEN)[0]\n","\n","text = \"that movie was just amazing, so amazing\"\n","encoded = encode_text(text)\n","print(encoded)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jzanxT0xEGVI","executionInfo":{"status":"ok","timestamp":1707233998272,"user_tz":-330,"elapsed":443,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"124836d7-06cc-4861-c3ad-7a64fbe4ae86"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n","1641221/1641221 [==============================] - 0s 0us/step\n","[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0  12  17  13  40 477  35 477]\n"]}]},{"cell_type":"code","source":["# while were at it lets make a decode function\n","\n","reverse_word_index = {value: key for (key, value) in word_index.items()}\n","\n","def decode_integers(integers):\n","    PAD = 0\n","    text = \"\"\n","    for num in integers:\n","      if num != PAD:\n","        text += reverse_word_index[num] + \" \"\n","\n","    return text[:-1]\n","\n","print(decode_integers(encoded))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HSsqn5ImE4LS","executionInfo":{"status":"ok","timestamp":1707234074627,"user_tz":-330,"elapsed":526,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"fbdf5b6e-9e63-4752-b106-d37d8fa30cb1"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["that movie was just amazing so amazing\n"]}]},{"cell_type":"code","source":["# now time to make a prediction\n","\n","def predict(text):\n","  encoded_text = encode_text(text)\n","  pred = np.zeros((1,250))\n","  pred[0] = encoded_text\n","  result = model.predict(pred)\n","  print(result[0])\n","\n","positive_review = \"That movie was! really loved it and would great watch it again because it was amazingly great\"\n","predict(positive_review)\n","\n","negative_review = \"that movie really sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\n","predict(negative_review)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CuXlIFbHFJlO","executionInfo":{"status":"ok","timestamp":1707234307349,"user_tz":-330,"elapsed":1281,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"f5954aef-270c-4f16-d66a-fc94f146268c"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 658ms/step\n","[0.935653]\n","1/1 [==============================] - 0s 29ms/step\n","[0.127334]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"GxBgv8IMGCMA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# RNN Play Generator"],"metadata":{"id":"eT51GdEKGdxU"}},{"cell_type":"code","source":["%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n","from keras.preprocessing import sequence\n","import keras\n","import tensorflow as tf\n","import os\n","import numpy as np"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C62EgiiKGfo5","executionInfo":{"status":"ok","timestamp":1707234467157,"user_tz":-330,"elapsed":14,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"1101b1d3-b79f-43cd-e527-bda119736af1"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"]}]},{"cell_type":"code","source":["path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gu4tM5FFGpXs","executionInfo":{"status":"ok","timestamp":1707235271817,"user_tz":-330,"elapsed":451,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"5ae240c1-5a3a-4578-9a16-99f626d1037a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n","1115394/1115394 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["# Read, then decode for py2 compat.\n","text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n","# length of text is the number of characters in it\n","print ('Length of text: {} characters'.format(len(text)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M4MhDLaBKHRD","executionInfo":{"status":"ok","timestamp":1707235430922,"user_tz":-330,"elapsed":4,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"f9963030-3186-47d7-f3cc-1728201ba119"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of text: 1115394 characters\n"]}]},{"cell_type":"code","source":["# Take a look at the first 250 characters in text\n","print(text[:250])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3gMp7xA9KUl9","executionInfo":{"status":"ok","timestamp":1707235441429,"user_tz":-330,"elapsed":6,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"39c08dc6-ed28-49b6-f8d6-0bc9f3eae81d"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you know Caius Marcius is chief enemy to the people.\n","\n"]}]},{"cell_type":"code","source":["vocab = sorted(set(text))\n","# Creating a mapping from unique characters to indices\n","char2idx = {u:i for i, u in enumerate(vocab)}\n","idx2char = np.array(vocab)\n","\n","def text_to_int(text):\n","  return np.array([char2idx[c] for c in text])\n","\n","text_as_int = text_to_int(text)"],"metadata":{"id":"nbyQmdpvKXZ5","executionInfo":{"status":"ok","timestamp":1707235458767,"user_tz":-330,"elapsed":4,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# lets look at how part of our text is encoded\n","print(\"Text:\", text[:13])\n","print(\"Encoded:\", text_to_int(text[:13]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fwkE6Y7wKbpk","executionInfo":{"status":"ok","timestamp":1707235593549,"user_tz":-330,"elapsed":4,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"36aef750-fa8a-4ee9-d210-679e256802ae"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Text: First Citizen\n","Encoded: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"]}]},{"cell_type":"code","source":["def int_to_text(ints):\n","  try:\n","    ints = ints.numpy()\n","  except:\n","    pass\n","  return ''.join(idx2char[ints])\n","\n","print(int_to_text(text_as_int[:13]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vWcQCGiBK8nE","executionInfo":{"status":"ok","timestamp":1707235603127,"user_tz":-330,"elapsed":445,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"df060aec-75c3-4155-b835-c5fd5b65b95e"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["First Citizen\n"]}]},{"cell_type":"code","source":["seq_length = 100  # length of sequence for a training example\n","examples_per_epoch = len(text)//(seq_length+1)\n","\n","# Create training examples / targets\n","char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"],"metadata":{"id":"s1CRibwmK-yK","executionInfo":{"status":"ok","timestamp":1707235651713,"user_tz":-330,"elapsed":437,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"],"metadata":{"id":"RBzHdqz6LKnq","executionInfo":{"status":"ok","timestamp":1707235711380,"user_tz":-330,"elapsed":4,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def split_input_target(chunk):  # for the example: hello\n","    input_text = chunk[:-1]  # hell\n","    target_text = chunk[1:]  # ello\n","    return input_text, target_text  # hell, ello\n","\n","dataset = sequences.map(split_input_target)  # we use map to apply the above function to every entry"],"metadata":{"id":"ZlrWEDe1LZT-","executionInfo":{"status":"ok","timestamp":1707235729913,"user_tz":-330,"elapsed":719,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["for x, y in dataset.take(2):\n","  print(\"\\n\\nEXAMPLE\\n\")\n","  print(\"INPUT\")\n","  print(int_to_text(x))\n","  print(\"\\nOUTPUT\")\n","  print(int_to_text(y))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w-hWmP9jLdrN","executionInfo":{"status":"ok","timestamp":1707235749742,"user_tz":-330,"elapsed":4,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"27536f15-25a7-49aa-a076-5ad9fad656c4"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","EXAMPLE\n","\n","INPUT\n","First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You\n","\n","OUTPUT\n","irst Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You \n","\n","\n","EXAMPLE\n","\n","INPUT\n","are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you \n","\n","OUTPUT\n","re all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you k\n"]}]},{"cell_type":"code","source":["BATCH_SIZE = 64\n","VOCAB_SIZE = len(vocab)  # vocab is number of unique characters\n","EMBEDDING_DIM = 256\n","RNN_UNITS = 1024\n","\n","# Buffer size to shuffle the dataset\n","# (TF data is designed to work with possibly infinite sequences,\n","# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n","# it maintains a buffer in which it shuffles elements).\n","BUFFER_SIZE = 10000\n","\n","data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"],"metadata":{"id":"JyES8-7WLisG","executionInfo":{"status":"ok","timestamp":1707235929902,"user_tz":-330,"elapsed":482,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","  model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n","                              batch_input_shape=[batch_size, None]),\n","    tf.keras.layers.LSTM(rnn_units,\n","                        return_sequences=True,\n","                        stateful=True,\n","                        recurrent_initializer='glorot_uniform'),\n","    tf.keras.layers.Dense(vocab_size)\n","  ])\n","  return model\n","\n","model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dFP-VzlGMOj8","executionInfo":{"status":"ok","timestamp":1707235983486,"user_tz":-330,"elapsed":9,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"06d39b6b-a871-4355-a143-ddd802eb4dfc"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (64, None, 256)           16640     \n","                                                                 \n"," lstm_1 (LSTM)               (64, None, 1024)          5246976   \n","                                                                 \n"," dense_1 (Dense)             (64, None, 65)            66625     \n","                                                                 \n","=================================================================\n","Total params: 5330241 (20.33 MB)\n","Trainable params: 5330241 (20.33 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["for input_example_batch, target_example_batch in data.take(1):\n","  example_batch_predictions = model(input_example_batch)  # ask our model for a prediction on our first batch of training data (64 entries)\n","  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")  # print out the output shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4-GtVqsrMbD4","executionInfo":{"status":"ok","timestamp":1707236180103,"user_tz":-330,"elapsed":2971,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"efdc6950-ec47-4dae-b618-06d4a6b5d307"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"]}]},{"cell_type":"code","source":["# we can see that the predicition is an array of 64 arrays, one for each entry in the batch\n","print(len(example_batch_predictions))\n","print(example_batch_predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dVZ0z6JHNK0h","executionInfo":{"status":"ok","timestamp":1707236188878,"user_tz":-330,"elapsed":521,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"797ca780-e122-414f-c379-a879fc6099b0"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["64\n","tf.Tensor(\n","[[[-2.37431820e-03 -5.47135063e-03 -1.00572072e-02 ... -3.73502146e-03\n","    3.15275020e-03  2.63041817e-03]\n","  [-3.57317016e-03 -8.10095295e-03 -4.89645172e-03 ... -2.78984942e-03\n","    8.16932414e-03  2.32312409e-03]\n","  [-4.74681240e-03 -7.93812145e-03 -9.45764594e-03 ... -1.43070263e-03\n","    4.24548052e-04  4.70852759e-03]\n","  ...\n","  [ 5.04184607e-03 -5.29281143e-03  3.21232900e-03 ...  1.03200378e-03\n","    3.38081480e-03  1.03446189e-04]\n","  [ 2.44308892e-03 -9.71749984e-03  3.85338278e-03 ...  1.52525678e-03\n","    7.92136509e-03  2.57126335e-03]\n","  [ 4.56746016e-03 -1.10994447e-02  1.16132689e-03 ...  7.63508433e-05\n","    5.95606957e-03  6.65921252e-04]]\n","\n"," [[-2.37431820e-03 -5.47135063e-03 -1.00572072e-02 ... -3.73502146e-03\n","    3.15275020e-03  2.63041817e-03]\n","  [ 5.31854108e-04  1.18309376e-03 -8.21532123e-03 ... -5.10108937e-03\n","    4.92013618e-03  5.18953335e-03]\n","  [-6.95144292e-04  2.09625205e-03 -3.43981315e-03 ... -5.94932353e-03\n","    3.71287554e-03  6.42467057e-04]\n","  ...\n","  [-5.76381106e-03 -1.01705603e-02 -7.90748652e-03 ... -4.76317527e-03\n","   -3.16496473e-04 -4.25234996e-03]\n","  [-4.58749756e-03 -7.58593157e-03 -6.78043813e-03 ...  6.33916771e-03\n","   -1.73753127e-04 -2.79757427e-03]\n","  [-4.35255934e-03 -7.61773624e-03 -8.88358057e-03 ...  8.61896377e-04\n","    7.27710407e-03 -3.62157589e-03]]\n","\n"," [[-3.90502019e-03  1.31762319e-03 -5.20365592e-03 ...  7.12377345e-03\n","   -4.56304941e-03 -1.94557419e-03]\n","  [-3.04915057e-03  1.83306425e-03 -6.95902063e-03 ...  1.49879772e-02\n","   -4.70693875e-03 -1.43928337e-03]\n","  [ 7.29042338e-04  1.74783031e-03  2.57856213e-04 ...  8.65479186e-03\n","   -1.13215409e-02 -8.92853644e-03]\n","  ...\n","  [-1.53040164e-03  1.54580758e-03 -8.58930638e-04 ... -7.94496946e-03\n","    1.75582292e-03  6.68199640e-03]\n","  [-7.98163936e-04  1.19507546e-03  6.31806627e-03 ... -8.59958492e-03\n","   -6.67559821e-03 -1.69110950e-03]\n","  [ 1.35767763e-03  2.21937126e-03  3.98799405e-03 ... -4.84980270e-03\n","   -8.46054498e-03 -2.56464817e-03]]\n","\n"," ...\n","\n"," [[-1.15908217e-03  2.59221066e-03 -2.00467696e-03 ... -5.22457005e-04\n","   -3.52264149e-03 -3.51141440e-03]\n","  [-3.24517000e-03 -3.19871842e-03 -1.17851235e-02 ... -3.85922892e-03\n","    8.89132731e-04  3.35108722e-04]\n","  [-7.07174372e-03 -2.32439162e-03 -7.24099670e-03 ... -1.69554469e-03\n","    7.51792872e-03  1.93333719e-03]\n","  ...\n","  [-8.50421749e-03 -1.49924005e-03  9.91842244e-03 ... -8.99867062e-03\n","    6.89710490e-04 -3.94307915e-03]\n","  [-7.54588610e-03  3.24593345e-03  9.39538330e-03 ...  8.32951628e-07\n","    2.18603387e-03 -1.87040877e-03]\n","  [-8.05991981e-03  4.35475446e-03  7.13959709e-03 ...  1.95632601e-04\n","   -2.41027167e-03 -4.37708758e-03]]\n","\n"," [[-1.15908217e-03  2.59221066e-03 -2.00467696e-03 ... -5.22457005e-04\n","   -3.52264149e-03 -3.51141440e-03]\n","  [-2.06879480e-03  2.55669095e-03 -8.81325454e-04 ... -2.37582508e-03\n","   -9.27054440e-04 -4.30662977e-03]\n","  [-7.30407797e-03  4.16452240e-04  1.17562688e-03 ... -1.92758860e-03\n","    6.05426589e-03 -2.85708811e-04]\n","  ...\n","  [-7.22066034e-03 -1.37666194e-03 -2.25357804e-03 ... -4.26107785e-03\n","   -3.48345144e-04 -7.14229420e-04]\n","  [-4.12668101e-03  2.81321188e-03 -1.76176114e-03 ... -7.35871680e-03\n","    2.13835388e-03  3.67061421e-03]\n","  [-4.10338212e-03  4.09933366e-03  1.63743435e-03 ... -8.84018000e-03\n","    6.53201248e-04  4.13996167e-03]]\n","\n"," [[ 1.90343033e-03 -1.25820667e-03 -5.25595853e-03 ...  3.12027684e-03\n","   -3.58826225e-03 -2.33490672e-03]\n","  [ 3.66567308e-03  1.73316756e-03 -7.05485605e-03 ...  1.87140552e-03\n","   -1.85728609e-03 -5.18898945e-04]\n","  [-4.97272122e-04 -3.02143279e-03 -4.62089479e-03 ...  3.69779672e-03\n","    4.66591329e-04 -5.06642088e-03]\n","  ...\n","  [-3.02804308e-03 -2.66431784e-03 -5.21525089e-03 ... -1.57944765e-03\n","   -6.15380704e-03 -3.69690172e-03]\n","  [-1.24177942e-03 -5.35863731e-03 -4.93134605e-03 ... -4.83057275e-03\n","   -3.38106230e-03 -5.16010402e-03]\n","  [-1.00413617e-03 -3.74812144e-03 -5.63668273e-03 ... -3.04150861e-03\n","   -6.09378889e-03 -3.52900638e-03]]], shape=(64, 100, 65), dtype=float32)\n"]}]},{"cell_type":"code","source":["# lets examine one prediction\n","pred = example_batch_predictions[0]\n","print(len(pred))\n","print(pred)\n","# notice this is a 2d array of length 100, where each interior array is the prediction for the next character at each time step"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i9trWsOANNt-","executionInfo":{"status":"ok","timestamp":1707236204715,"user_tz":-330,"elapsed":432,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"a322b184-b5c1-4ee9-cb9e-32930f589b68"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["100\n","tf.Tensor(\n","[[-2.3743182e-03 -5.4713506e-03 -1.0057207e-02 ... -3.7350215e-03\n","   3.1527502e-03  2.6304182e-03]\n"," [-3.5731702e-03 -8.1009530e-03 -4.8964517e-03 ... -2.7898494e-03\n","   8.1693241e-03  2.3231241e-03]\n"," [-4.7468124e-03 -7.9381214e-03 -9.4576459e-03 ... -1.4307026e-03\n","   4.2454805e-04  4.7085276e-03]\n"," ...\n"," [ 5.0418461e-03 -5.2928114e-03  3.2123290e-03 ...  1.0320038e-03\n","   3.3808148e-03  1.0344619e-04]\n"," [ 2.4430889e-03 -9.7174998e-03  3.8533828e-03 ...  1.5252568e-03\n","   7.9213651e-03  2.5712634e-03]\n"," [ 4.5674602e-03 -1.1099445e-02  1.1613269e-03 ...  7.6350843e-05\n","   5.9560696e-03  6.6592125e-04]], shape=(100, 65), dtype=float32)\n"]}]},{"cell_type":"code","source":["# and finally well look at a prediction at the first timestep\n","time_pred = pred[0]\n","print(len(time_pred))\n","print(time_pred)\n","# and of course its 65 values representing the probabillity of each character occuring next"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3OUzw2x_NRuc","executionInfo":{"status":"ok","timestamp":1707236214831,"user_tz":-330,"elapsed":4,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"ddfaee9c-ffd3-4798-d4f4-a98682b2e6c0"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["65\n","tf.Tensor(\n","[-0.00237432 -0.00547135 -0.01005721  0.00546232 -0.00102907 -0.00260884\n","  0.00152438 -0.00155765 -0.00083136 -0.00206626 -0.00303523  0.00109406\n"," -0.00016082 -0.00274255  0.00257152  0.00017511 -0.00190918  0.00812275\n"," -0.0033444   0.00202222  0.0037367   0.00269834  0.00210156 -0.001531\n"," -0.00187128  0.00277537  0.0032971   0.00079104 -0.00111711  0.00058686\n","  0.00133974  0.00200258 -0.00059453 -0.00291448  0.00191896 -0.00206861\n","  0.01194951  0.00021201  0.0026182   0.00166131 -0.00435438 -0.00317055\n"," -0.00498145  0.00802493 -0.00087644  0.00382206 -0.00218373 -0.00163302\n"," -0.00606679  0.00087754 -0.00132161  0.00327915  0.00333717  0.00012884\n"," -0.00413076  0.00216884  0.00942067  0.00116553  0.00023523 -0.00144204\n","  0.00237971 -0.00312414 -0.00373502  0.00315275  0.00263042], shape=(65,), dtype=float32)\n"]}]},{"cell_type":"code","source":["# If we want to determine the predicted character we need to sample the output distribution (pick a value based on probabillity)\n","sampled_indices = tf.random.categorical(pred, num_samples=1)\n","\n","# now we can reshape that array and convert all the integers to numbers to see the actual characters\n","sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n","predicted_chars = int_to_text(sampled_indices)\n","\n","predicted_chars  # and this is what the model predicted for training sequence 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"7x5PxQ0rNUKa","executionInfo":{"status":"ok","timestamp":1707236224138,"user_tz":-330,"elapsed":16,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"f9796afe-777e-4aba-e09f-9fa9b78baabd"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'E?,qFXT:y:TD!;bRyLRu?GUGH!.A\\ngfpWJ uAekO gT:PWS WUBWV!EUUomulKYpqXE&-QeYHBMO\\nzxDIaxvGinP$kcbJdov,zBt'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["def loss(labels, logits):\n","  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"],"metadata":{"id":"1E0BzseONWgf","executionInfo":{"status":"ok","timestamp":1707236235839,"user_tz":-330,"elapsed":4,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='adam', loss=loss)"],"metadata":{"id":"0nX4jH7wNZTS","executionInfo":{"status":"ok","timestamp":1707236243694,"user_tz":-330,"elapsed":430,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# Directory where the checkpoints will be saved\n","checkpoint_dir = './training_checkpoints'\n","# Name of the checkpoint files\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","\n","checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True)"],"metadata":{"id":"xRhD5syuNbL5","executionInfo":{"status":"ok","timestamp":1707236251948,"user_tz":-330,"elapsed":8,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["history = model.fit(data, epochs=50, callbacks=[checkpoint_callback])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MynpeKARNdO1","executionInfo":{"status":"ok","timestamp":1707237085296,"user_tz":-330,"elapsed":826591,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"f8ccde36-cb7c-475e-e52b-75b037b3149a"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","172/172 [==============================] - 16s 67ms/step - loss: 2.7925\n","Epoch 2/50\n","172/172 [==============================] - 14s 65ms/step - loss: 2.0907\n","Epoch 3/50\n","172/172 [==============================] - 13s 65ms/step - loss: 1.8224\n","Epoch 4/50\n","172/172 [==============================] - 13s 65ms/step - loss: 1.6622\n","Epoch 5/50\n","172/172 [==============================] - 13s 66ms/step - loss: 1.5605\n","Epoch 6/50\n","172/172 [==============================] - 14s 68ms/step - loss: 1.4914\n","Epoch 7/50\n","172/172 [==============================] - 13s 67ms/step - loss: 1.4414\n","Epoch 8/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.4038\n","Epoch 9/50\n","172/172 [==============================] - 13s 67ms/step - loss: 1.3722\n","Epoch 10/50\n","172/172 [==============================] - 14s 68ms/step - loss: 1.3441\n","Epoch 11/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.3202\n","Epoch 12/50\n","172/172 [==============================] - 14s 68ms/step - loss: 1.2975\n","Epoch 13/50\n","172/172 [==============================] - 14s 69ms/step - loss: 1.2765\n","Epoch 14/50\n","172/172 [==============================] - 14s 70ms/step - loss: 1.2562\n","Epoch 15/50\n","172/172 [==============================] - 14s 69ms/step - loss: 1.2373\n","Epoch 16/50\n","172/172 [==============================] - 14s 70ms/step - loss: 1.2158\n","Epoch 17/50\n","172/172 [==============================] - 14s 69ms/step - loss: 1.1967\n","Epoch 18/50\n","172/172 [==============================] - 14s 70ms/step - loss: 1.1750\n","Epoch 19/50\n","172/172 [==============================] - 14s 69ms/step - loss: 1.1532\n","Epoch 20/50\n","172/172 [==============================] - 14s 69ms/step - loss: 1.1323\n","Epoch 21/50\n","172/172 [==============================] - 14s 69ms/step - loss: 1.1084\n","Epoch 22/50\n","172/172 [==============================] - 14s 70ms/step - loss: 1.0848\n","Epoch 23/50\n","172/172 [==============================] - 14s 70ms/step - loss: 1.0600\n","Epoch 24/50\n","172/172 [==============================] - 14s 70ms/step - loss: 1.0343\n","Epoch 25/50\n","172/172 [==============================] - 14s 70ms/step - loss: 1.0079\n","Epoch 26/50\n","172/172 [==============================] - 15s 71ms/step - loss: 0.9805\n","Epoch 27/50\n","172/172 [==============================] - 14s 71ms/step - loss: 0.9521\n","Epoch 28/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.9251\n","Epoch 29/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.8967\n","Epoch 30/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.8693\n","Epoch 31/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.8418\n","Epoch 32/50\n","172/172 [==============================] - 14s 71ms/step - loss: 0.8138\n","Epoch 33/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.7872\n","Epoch 34/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.7628\n","Epoch 35/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.7392\n","Epoch 36/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.7150\n","Epoch 37/50\n","172/172 [==============================] - 14s 71ms/step - loss: 0.6930\n","Epoch 38/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.6740\n","Epoch 39/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.6534\n","Epoch 40/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.6365\n","Epoch 41/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.6190\n","Epoch 42/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.6031\n","Epoch 43/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.5888\n","Epoch 44/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.5726\n","Epoch 45/50\n","172/172 [==============================] - 14s 69ms/step - loss: 0.5620\n","Epoch 46/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.5497\n","Epoch 47/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.5376\n","Epoch 48/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.5281\n","Epoch 49/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.5167\n","Epoch 50/50\n","172/172 [==============================] - 14s 70ms/step - loss: 0.5086\n"]}]},{"cell_type":"code","source":["model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"],"metadata":{"id":"BQHiScRBNe9N","executionInfo":{"status":"ok","timestamp":1707237086040,"user_tz":-330,"elapsed":747,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n","model.build(tf.TensorShape([1, None]))"],"metadata":{"id":"Cy5SWIeMNkQQ","executionInfo":{"status":"ok","timestamp":1707237086040,"user_tz":-330,"elapsed":17,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["checkpoint_num = 10\n","model.load_weights(\"./training_checkpoints/ckpt_\" + str(checkpoint_num))\n","model.build(tf.TensorShape([1, None]))"],"metadata":{"id":"RJxS0tD2Nmnb","executionInfo":{"status":"ok","timestamp":1707237159117,"user_tz":-330,"elapsed":3,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["def generate_text(model, start_string):\n","  # Evaluation step (generating text using the learned model)\n","\n","  # Number of characters to generate\n","  num_generate = 800\n","\n","  # Converting our start string to numbers (vectorizing)\n","  input_eval = [char2idx[s] for s in start_string]\n","  input_eval = tf.expand_dims(input_eval, 0)\n","\n","  # Empty string to store our results\n","  text_generated = []\n","\n","  # Low temperatures results in more predictable text.\n","  # Higher temperatures results in more surprising text.\n","  # Experiment to find the best setting.\n","  temperature = 1.0\n","\n","  # Here batch size == 1\n","  model.reset_states()\n","  for i in range(num_generate):\n","      predictions = model(input_eval)\n","      # remove the batch dimension\n","\n","      predictions = tf.squeeze(predictions, 0)\n","\n","      # using a categorical distribution to predict the character returned by the model\n","      predictions = predictions / temperature\n","      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n","\n","      # We pass the predicted character as the next input to the model\n","      # along with the previous hidden state\n","      input_eval = tf.expand_dims([predicted_id], 0)\n","\n","      text_generated.append(idx2char[predicted_id])\n","\n","  return (start_string + ''.join(text_generated))"],"metadata":{"id":"Fivio0M_NpUu","executionInfo":{"status":"ok","timestamp":1707237163030,"user_tz":-330,"elapsed":523,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["inp = input(\"Type a starting string: \")\n","print(generate_text(model, inp))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HCm9blusNsP6","executionInfo":{"status":"ok","timestamp":1707237233103,"user_tz":-330,"elapsed":18909,"user":{"displayName":"Jils Patel","userId":"02781128952594085614"}},"outputId":"9ab6c559-b703-435b-c31e-9f81c812ae9c"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Type a starting string: apple\n","appleadon's require and die block--\n","To nothing more than Perca's sou to-done.\n","Farther, I prithee, leist upon it not oath.\n","I none of bold, then way to think\n","'Tis gollory, and quickly, who At Paulina\n","and read your vict be; pardo? O, to be quiet\n","And flet us to't:\n","Lords, thus; I am song corposion would not.\n","\n","KING RICHARD III:\n","Sunnoc and hacts moctagnors. 'ha resoleity,\n","And where finds the\n","queen do we hear.\n","\n","QUEEN MARGARET:\n","I will't know you were no more than zalack and blown,\n","Three wermiatedeaments, so finds another and I can a better breath.\n","\n","KING RICHARD III:\n","Good lorrs,\n","But that I say, bring me bold,\n","To ase I in that; be arro; but they\n","Have sains the gave by a death; you re jest in auit Henry's blood\n","With from me with ink beginst years within Edward. Now, lords, I know you, sir, thou\n","prayers, di\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"bwWLNMczQ8S9"},"execution_count":null,"outputs":[]}]}